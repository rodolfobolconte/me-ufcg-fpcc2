---
title: "2 - Execução de Modelos de Aprendizagem"
author: Rodolfo Bolconte
date: 26/06/21
output:
    #word_document: default
    html_document:
        rmdformats::readthedown
---

<style>
body {
text-align: justify}
</style>

```{r echo=FALSE}
knitr::opts_chunk$set(tidy = TRUE,
                      warning=FALSE, message=FALSE,
                      fig.width = 6,
                      fig.height = 6,
                      fig.align="center"
                      )
```

Repositório dos Dados Originais: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&CycleBeginYear=2015
Documentação dos Dados: https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DIQ_I.htm

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(boot)
library(broom)
library(grid)
library(gridExtra)
library(quantreg)
library(scales)
library(caret)
```

## Carregamento dos Dados

```{r}
#CARREGAMENTO DO CONJUNTO DE DADO
dados = read_csv(here::here("code/diabetes_random.csv"))

dados = dados %>% mutate(diabetico=if_else(diabetico==2, 0, 1))

dataset = dados[2:10]

dataset$diabetico = factor(dataset$diabetico, levels=c(0,1))
```

```{r}
#REAMOSTRAGEM DOS DADOS UTILIZANDO HOLDOUT 56:14:30
library(caTools)
set.seed(123)

#56% DOS DADOS PARA TREINO = 78 AMOSTRAS
split_train = sample.split(dataset$diabetico, SplitRatio=78)
ds_train = subset(dataset, split_train == T)

#RESTANTE DOS DADOS
ds_restante = subset(dataset, split_train == F)

#14% DOS DADOS PARA VALIDAÇÃO = 20 AMOSTRAS
split_validation = sample.split(ds_restante$diabetico, SplitRatio=20)
ds_validation = subset(ds_restante, split_validation == T)

#30% DOS DADOS RESTANTES DO CONJUNTO ORIGINAL PARA TESTE = 42 AMOSTRAS
ds_test = subset(ds_restante, split_validation == F)
```


```{r}
# FORMULAS
# accuracy = (tn+tp)/(tn+fn+fp+tp)
# sensitivity = (tp)/(tp+fn)
# specificity = (tn)/(tn+fp)

#FUNÇÃO DE ACURÁCIA
calculo_metricas <- function(original, prediction) {
  confusion_matrix = table(original, prediction)
  tn = confusion_matrix[1]
  fn = confusion_matrix[2]
  fp = confusion_matrix[3]
  tp = confusion_matrix[4]

  accuracy = (tn+tp)/(tn+fn+fp+tp)
  sensitivity = (tp)/(tp+fn)
  specificity = (tn)/(tn+fp)
  
  c(accuracy,sensitivity,specificity)
}
```


```{r}
#EXECUÇÃO DO RANDOM FOREST
library(randomForest)

#CRIAÇÃO E TREINO DO MODELO
rf_model = randomForest(x=ds_train[-9],
                                    y=ds_train$diabetico,
                                    ntree=50, random_state=0)

#PREVISÃO DOS DADOS DE VALIDAÇÃO
rf_prev_validation = predict(rf_model, ds_validation)
calculo_metricas(ds_validation$diabetico, rf_prev_validation)

#PREVISAO DOS DADOS DE TESTE
rf_prev_test = predict(rf_model, ds_test)
calculo_metricas(ds_test$diabetico, rf_prev_test)
rf_data_ic = data.frame(original=ds_test$diabetico, previsao=rf_prev_test)
```

```{r}
#EXECUÇÃO DO SVM
library(e1071)

#CRIAÇÃO E TREINO DO MODELO
svm_model = randomForest(x=ds_train[-9],
                        y=ds_train$diabetico)

#PREVISÃO DOS DADOS DE VALIDAÇÃO
svm_prev_validation = predict(svm_model, ds_validation)
calculo_metricas(ds_validation$diabetico, svm_prev_validation)

#PREVISAO DOS DADOS DE TESTE
svm_prev_test = predict(svm_model, ds_test)
calculo_metricas(ds_test$diabetico, svm_prev_test)
svm_data_ic = data.frame(original=ds_test$diabetico, previsao=svm_prev_test)
```



```{r}
#CALCULO DE THETA
metricas <- function(dataset, indices) {
  random = dataset %>%
    slice(indices)
  
  calculo_metricas(random$original, random$previsao)
}

#FUNÇÃO QUE EXECUTA BOOTSTRAP E CALCULA THETA
ic_acuracia = function(dataset, tipo_modelo) {
    
  #GERAÇÃO DO BOOTSTRAP
  resultado_bootstrap = boot(data = dataset,
         statistic = metricas,
         R = 2000) %>%
  tidy(conf.level = .95,
       conf.method = "bca",
       conf.int = TRUE)

  resultado_bootstrap %>% mutate(modelo=tipo_modelo, metrica=c('Accuracy', 'Sensitivity', 'Specificity'))
}
```


```{r}
rf_ic = ic_acuracia(rf_data_ic, "Random Forest")
svm_ic = ic_acuracia(svm_data_ic, "Support Vector Machine")

models_data_ic = bind_rows(rf_ic, svm_ic) ; models_data_ic
```

```{r fig.width = 7, fig.height = 5}
models_data_ic %>% 
  ggplot(aes(y=metrica)) +
  facet_wrap(~modelo, ) +
  geom_point(aes(x=statistic), size=4) +
  geom_errorbar(aes(xmin=conf.low, xmax=conf.high), width=.13) +
  labs(x="\nIntervalos de Confiança de Métricas por Modelos", y="Métrica\n") +
  theme(text=element_text(size=16),
        panel.margin = unit(1, "lines")) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(limits = c(0,1))

ggsave("3-f-ic-previsao-modelos.pdf")
```


```{r}
#CALCULO DE THETA
diferenca_acuracia <- function(rf_dataset, indices, svm_dataset) {
  rf_random = rf_dataset %>%
    slice(indices)
  
  svm_random = svm_dataset %>%
    slice(indices)
  
  calculo_metricas(rf_random$original, rf_random$previsao) - calculo_metricas(svm_random$original, svm_random$previsao)
}


#FUNÇÃO QUE EXECUTA BOOTSTRAP E CALCULA THETA
ic_diferenca_acuracia = function(rf_dataset, svm_dataset) {
    
  #GERAÇÃO DO BOOTSTRAP
  resultado_bootstrap = boot(data = rf_dataset,
         statistic = diferenca_acuracia,
         R = 2000,
         svm_dataset=svm_dataset) %>%
  tidy(conf.level = .95,
       conf.method = "basic",
       conf.int = TRUE)

  resultado_bootstrap %>% mutate(metrica=c('Accuracy', 'Sensitivity', 'Specificity'))
}
```

```{r}
diferenca_modelos_ic = ic_diferenca_acuracia(rf_data_ic, svm_data_ic) ; diferenca_modelos_ic
```

```{r fig.width = 7, fig.height = 5}
diferenca_metricas_plot = diferenca_modelos_ic %>% 
  ggplot(aes(y=metrica)) +
  geom_point(aes(x=statistic), size=4) +
  geom_errorbar(aes(xmin=conf.low, xmax=conf.high), width=.15) +
  labs(x=NULL, y=NULL) +
  geom_vline(xintercept = 0) +
  geom_text(aes(x=statistic, label = metrica), hjust = 2, vjust=-.3) +
  scale_x_continuous(limits=c(-1,1)) +
  scale_y_discrete(labels=NULL)

g = grid.arrange(diferenca_metricas_plot,
             left = textGrob("Support Vector Machine",
                               gp = gpar(fontsize=16), r=90),
             right = textGrob("Random Forest",
                               gp = gpar(fontsize=16), r=270),
             bottom = textGrob("Intervalo de Confiança da Diferença de Métricas",
                               gp = gpar(fontsize=16)))

g

ggsave("3-f-ic-diferenca-modelos.pdf", g)
```